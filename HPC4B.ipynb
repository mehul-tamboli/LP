{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr_9wEsaAVSL",
        "outputId": "11a4b10c-dad0-484e-deb4-9db3f7869f57"
      },
      "outputs": [],
      "source": [
        "%%writefile matrix_mul.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 16  \n",
        "\n",
        "\n",
        "__global__ void matrixMulKernel(float *A, float *B, float *C, int n) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;  \n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;  \n",
        "\n",
        "    if (row < n && col < n) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < n; ++k) {\n",
        "            sum += A[row * n + k] * B[k * n + col];\n",
        "        }\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float);\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    \n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = 1.0f;\n",
        "        h_B[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    \n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 blocksPerGrid((N + 15) / 16, (N + 15) / 16);\n",
        "    matrixMulKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    \n",
        "    printf(\"Top-left 4x4 result matrix:\\n\");\n",
        "    for (int i = 0; i < 4; i++) {\n",
        "        for (int j = 0; j < 4; j++) {\n",
        "            printf(\"%.1f \", h_C[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQNGJET_Ajze",
        "outputId": "916a9bd8-2c1a-4b3d-b9e8-1434f4ba6d86"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul\n",
        "!./matrix_mul"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
